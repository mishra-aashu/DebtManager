import pandas as pd
from fastapi import FastAPI, File, UploadFile, Depends, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from supabase_client import supabase  # Assuming this is the initialized Supabase client
from auth import auth_service, get_current_user, get_current_admin_user
from pydantic import BaseModel
from typing import List, Dict, Any
import os
from datetime import datetime
from dotenv import load_dotenv

dotenv_path = os.path.join(os.path.dirname(__file__), '.env')
load_dotenv(dotenv_path=dotenv_path)

# ============================================
# PYDANTIC MODELS
# ============================================

class UserLogin(BaseModel):
    username: str
    password: str

class Token(BaseModel):
    access_token: str
    token_type: str
    user: Dict[str, Any]

class SqlQuery(BaseModel):
    query: str

class AllocationRequest(BaseModel):
    table_name: str

# ============================================
# APP INITIALIZATION
# ============================================

app = FastAPI(
    title="FedEx Debt Manager API",
    description="API for managing debt collection, processing, and allocation.",
    version="1.0.0"
)

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================
# AUTHENTICATION ENDPOINTS (Refactored for FastAPI)
# ============================================

@app.post("/api/auth/login", response_model=Token)
async def login(form_data: UserLogin):
    user_res = supabase.table("users").select("*").eq("username", form_data.username).execute()
    if not user_res.data:
        raise HTTPException(status_code=401, detail="Invalid username or password")
    
    user = user_res.data[0]

    if not auth_service.verify_password(form_data.password, user['password_hash']):
        raise HTTPException(status_code=401, detail="Invalid username or password")

    token = auth_service.generate_token(user)
    return {
        "access_token": token, 
        "token_type": "bearer",
        "user": {
            'id': user['id'],
            'username': user['username'],
            'role': user['role'],
            'agency_name': user.get('agency_name')
        }
    }

@app.get("/api/auth/verify")
async def verify_token(current_user: dict = Depends(get_current_user)):
    """Verify if token is still valid"""
    return {"success": True, "user": current_user}

# ============================================
# MASTER PLAN WORKFLOW ENDPOINTS
# ============================================

@app.post("/api/generate-schema", dependencies=[Depends(get_current_admin_user)])
async def generate_schema(file: UploadFile = File(...)):
    """
    Reads a CSV file, infers a SQL schema, and returns a CREATE TABLE statement.
    - Admin Only
    """
    try:
        df = pd.read_csv(file.file)
        table_name = os.path.splitext(file.filename)[0].lower().replace(" ", "_")
        
        columns_sql = []
        for col, dtype in df.dtypes.items():
            sql_type = "TEXT"
            if "int" in str(dtype): sql_type = "BIGINT"
            elif "float" in str(dtype): sql_type = "FLOAT"
            
            clean_col = col.lower().replace(" ", "_").replace("(", "").replace(")", "")
            columns_sql.append(f'"{clean_col}" {sql_type}')
        
        columns_sql.append('"risk_score" FLOAT DEFAULT 0')
        columns_sql.append('"assigned_agency" TEXT DEFAULT \'Unassigned\'')

        sql_query = f"CREATE TABLE IF NOT EXISTS {table_name} (id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, {', '.join(columns_sql)});"
        
        return {"sql_code": sql_query, "table_name": table_name}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")

@app.post("/api/execute-sql", dependencies=[Depends(get_current_admin_user)])
async def execute_sql_query(sql_query: SqlQuery):
    """
    Executes a given SQL query (e.g., CREATE TABLE) on the database.
    Requires a custom RPC function 'exec_sql' in Supabase.
    - Admin Only
    """
    try:
        # Note: This requires a plpgsql function in Supabase:
        # CREATE OR REPLACE FUNCTION exec_sql(query text) RETURNS void AS $
        # BEGIN EXECUTE query; END;
        # $ LANGUAGE plpgsql;
        supabase.rpc('exec_sql', {'query': sql_query.query}).execute()
        return {"status": "success", "message": "Table Created Successfully!"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/embed-data", dependencies=[Depends(get_current_admin_user)])
async def embed_csv_data(table_name: str, file: UploadFile = File(...)):
    """
    Takes a CSV file and a table name, and bulk-inserts the data into that table.
    - Admin Only
    """
    try:
        df = pd.read_csv(file.file)
        
        # Clean column names in DataFrame to match the schema
        df.columns = [col.lower().replace(' ', '_').replace('(', '').replace(')', '') for col in df.columns]
        
        records = df.to_dict(orient='records')
        
        # Supabase bulk insert
        supabase.table(table_name).insert(records).execute()
        
        return {"status": "completed", "rows_inserted": len(records)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error embedding data: {str(e)}")


@app.post("/api/run-allocation-logic", dependencies=[Depends(get_current_admin_user)])
async def allocate_agencies(request: AllocationRequest):
    """
    Fetches data, calculates risk, assigns agencies, and updates the database.
    - Admin Only
    """
    try:
        table_name = request.table_name
        response = supabase.table(table_name).select("id, amount, daysoverdue").execute()
        df = pd.DataFrame(response.data)

        # Ensure required columns exist
        if 'amount' not in df.columns or 'daysoverdue' not in df.columns:
            raise HTTPException(status_code=400, detail="Table must contain 'amount' and 'daysoverdue' columns.")

        # ML Logic as per user's request
        df['risk_score'] = (df['amount'] / 1000) * (df['daysoverdue'] / 30)
        df = df.sort_values(by='risk_score', ascending=False)
        
        agencies = ["Alpha Collections", "Beta Recovery"]
        assignments = [agencies[i % 2] for i in range(len(df))]
        df['assigned_agency'] = assignments
        
        # Prepare records for update
        update_records = df[['id', 'risk_score', 'assigned_agency']].to_dict(orient='records')

        # Bulk update in Supabase
        for record in update_records:
            supabase.table(table_name).update({
                "risk_score": record['risk_score'],
                "assigned_agency": record['assigned_agency']
            }).eq("id", record['id']).execute()
            
        return {"status": "allocation_done", "message": f"Agencies assigned to {len(update_records)} records."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error during allocation: {str(e)}")

# Health check endpoint
@app.get("/api/health")
def health_check():
    return {'status': 'healthy', 'timestamp': datetime.utcnow().isoformat()}

# To run the app: uvicorn app:app --reload --port 8000
if __name__ == "__main__":
    import uvicorn
    port = 5000
    print(f"Starting server on port: {port}")
    uvicorn.run(app, host="0.0.0.0", port=port)